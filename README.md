# BIASINSPECTOR: Detecting Bias in Structured Data through LLM Agents

This repository contains the anonymized implementation, evaluation scripts, and experimental data for our paper titled:  
**"BIASINSPECTOR: Detecting Bias in Structured Data through LLM Agents"**.

## ğŸ“ Repository Structure

submission/
â”‚
â”œâ”€â”€ agents/                          
â”‚   â”œâ”€â”€ bias_inspector_multi/         # Multi-Agent framework
â”‚   â”œâ”€â”€ bias_inspector_single/        # Single-Agent framework
â”‚   â”œâ”€â”€ react_agent/                  # ReAct-based Agent
â”‚   â””â”€â”€ self_reflection_agent/        # Self-reflection Agent
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ result_evaluation/            # Evaluation of final bias detection results
â”‚   â””â”€â”€ process_evaluation/           # Evaluation of reasoning steps and tool usage
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dataset&taskset/                      # Structured data used in experiments
â”‚   â”œâ”€â”€ eval_results/                 # CSV files containing evaluation results
â”‚   â””â”€â”€ logs/                         # Execution logs per agent and model
â”‚
â””â”€â”€ README.md                         # Project documentation


## ğŸ“‚ Data & Experimental Logs

All data used for experiments are located under the `data/` directory:

- `dataset/`: Structured datasets used for bias detection experiments.
- `eval_results/`: CSV files storing final evaluation metrics.
- `logs/`: Log files generated during agent execution across different LLMs (GPT-4o and Llama 3.3 70B).  
  Each file is named to reflect the agent and model used.

## ğŸš« Anonymity Notice

This repository has been anonymized in accordance with double-blind review requirements. 

For any questions or clarifications, please refer to the anonymous submission portal using the submission ID provided.